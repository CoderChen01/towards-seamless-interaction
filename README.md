<p align="center">
  <img src="assets/logo.png" alt="Project Logo" width="220"/>
</p>

<h1 align="center"> ğŸ¤–âœ¨ Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics </h1> 

<p align="center">
  <a href="./assets/paper.pdf">
    <img src="https://img.shields.io/badge/arXiv-to_appear_on_arXiv-b31b1b.svg?style=for-the-badge" />
  </a>
</p>

<p align="center">
  <strong>
    <a>Junjie Chen</a><sup>1,2</sup> Â·
    <a>Fei Wang</a><sup>1,2</sup> Â·
    <a>Zhihao Huang</a><sup>5,6</sup> Â·
    <a>Qing Zhou</a><sup>8</sup> Â·
    <a>Kun Li</a><sup>7</sup>
  </strong>
  <br/>
  <strong>
    <a target="_blank" href="https://scholar.google.com/citations?user=DsEONuMAAAAJ&hl=zh-CN">Dan Guo</a><sup>1</sup> Â·
    <a target="_blank" href="https://scholar.google.com/citations?user=AK9VF30AAAAJ&hl=en&authuser=1">Linfeng Zhang</a><sup>4</sup> Â·
    <a target="_blank" href="https://scholar.google.com/citations?user=ro8lzsUAAAAJ&hl=en">Xun Yang</a><sup>3</sup>
  </strong>
  <p align="center">
  <sup>1</sup> Hefei University of Technology &nbsp;&nbsp;Â·&nbsp;&nbsp;
  <sup>2</sup> IAI, Hefei Comprehensive National Science Center <br/>
  <sup>3</sup> USTC &nbsp;&nbsp;Â·&nbsp;&nbsp;
  <sup>4</sup> SJTU &nbsp;&nbsp;Â·&nbsp;&nbsp;
  <sup>5</sup> TeleAI, China Telecom &nbsp;&nbsp;Â·&nbsp;&nbsp;
  <sup>6</sup> Northwestern Polytechnical University<br/>
  <sup>7</sup> Hong Kong Baptist University &nbsp;&nbsp;Â·&nbsp;&nbsp;
  <sup>8</sup> Anhui Polytechnic University
  </p>
</p>

---

## ğŸ”¥ Highlights

- ğŸ§  **Causal turn-level formulation** for streaming conversational generation  
- ğŸ”„ **Unified talking & listening modeling** within a single framework  
- ğŸ§ğŸ—£ï¸ **Interleaved multimodal tokens** from both interlocutors  
- ğŸŒŠ **Diffusion-based 3D head decoding** for expressive and stochastic motion  
- ğŸ“‰ **15â€“30% error reduction** over strong baselines (e.g., DualTalk)

---

## ğŸš€ Overview

Human conversation is a continuous exchange of **speech and nonverbal cues**â€”including head nods, gaze shifts, and subtle expressions.  
Most existing approaches, however, treat **talking-head** and **listening-head** generation as *separate problems*, or rely on *non-causal full-sequence modeling* that is unsuitable for real-time interaction.

We propose a **causal, turn-level framework** for interactive 3D conversational head generation.  
Our method models dialogue as a sequence of **causally linked turns**, where each turn accumulates multimodal context from both participants to produce **coherent, responsive, and humanlike 3D head dynamics**.

<p align="center">
  <img src="assets/overview.svg" alt="Framework Overview" width="90%"/>
</p>

---

## ğŸ§© Method: TIMAR

**TIMAR (Turn-level Interleaved Masked AutoRegression)** is the core method proposed in this work.

### ğŸ§± Key Idea

- Represent conversation as **interleaved audioâ€“visual tokens**:
  - ğŸ‘¤ User speech + user head motion  
  - ğŸ¤– Agent speech + agent head motion  
- Perform:
  - ğŸ” **Bidirectional fusion within each turn** (intra-turn alignment)  
  - â±ï¸ **Strictly causal reasoning across turns** (inter-turn dependency)

This design mirrors how humans coordinate speaking and listening over time.

### âš™ï¸ Architecture

<p align="center">
  <img src="assets/method.svg" alt="TIMAR Architecture" width="90%"/>
</p>

**Core components:**
- ğŸ§  **Turn-Level Causal Attention (TLCA)**  
  - Bidirectional attention inside a turn  
  - Causal masking across turns (no future leakage)  
- ğŸŒŠ **Lightweight Diffusion Head**  
  - Predicts continuous 3D head motion  
  - Captures expressive stochasticity beyond deterministic regression  

---

## ğŸ§ª Experiments

We evaluate our framework on the **interactive 3D conversational head benchmark**, following the DualTalk protocol.

### ğŸ“Š Quantitative Results

<details>
<summary>Click to see the results</summary>
<p align="center">
  <img src="assets/quant_results.png" alt="Quantitative Results" width="90%"/>
</p>
</details>

<br/>

**Results at a glance:**
- â¬‡ï¸ **15â€“30% reduction** in Frechet Distance (FD) and MSE  
- ğŸ“ˆ Improved expressiveness and synchronization (SID â†‘)  
- ğŸŒ Strong generalization on **out-of-distribution conversations**

---

### ğŸ­ Qualitative Results

<details>
<summary>Click to see the results</summary>
<p align="center">
  <img src="assets/qual_results.png" alt="Qualitative Results" width="90%"/>
</p><br/>
</details>

<br/>

TIMAR produces:
- Natural listening behavior when the agent is silent  
- Context-aware reactions with longer conversational history  
- Smoother and more stable 3D head motion  

---

### ğŸ§© Ablation Studies

<details>
<summary>Click to see the results</summary>
<p align="center">
  <img src="assets/ablation-1.png" alt="Ablation Studies" width="90%"/>
  <img src="assets/ablation-2.png" alt="Ablation Studies" width="90%"/>
</p>
</details>

<br/>

We analyze the contribution of each design choice:
- âŒ MLP head vs ğŸŒŠ diffusion-based head  
- âŒ Full bidirectional attention vs âœ… turn-level causal attention  
- âŒ Encoderâ€“decoder vs âœ… encoder-only backbone  

Each component is critical for causal coherence and generalization.

---

## ğŸ“¦ Code Release

ğŸš§ **Code will be released soon!**  

The full implementation of **TIMAR**, including training and inference pipelines, will be publicly released.  
If you are interested, feel free to â­ï¸ this repository and check back later.

---

## ğŸ“š Citation

If you find this work useful, please consider citing:

```bibtex
To be updated